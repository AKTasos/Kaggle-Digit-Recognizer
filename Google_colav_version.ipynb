{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1IN7lZ-AfIaFFC78rpVMxZnRdOHALYvk8",
      "authorship_tag": "ABX9TyN3M59mJu7wwblr+DfhOGJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKTasos/Kaggle-Digit-Recognizer/blob/Conv2dSequential/Google_colav_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbit6jGjFFq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import math\n",
        "import time\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ7h4Ph2FiGE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7bClT6YFM6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f88bdbc-9bba-470f-b35f-7ca2b128924f"
      },
      "source": [
        "path = os.chdir(\"/content/drive/My Drive/kaggle digit/Kaggle Digit Recognizer\")\n",
        "print(os.listdir())\n",
        "data_path = str\n",
        "\n",
        "\n",
        "class TensorDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data_path) : \n",
        "        data = pd.read_csv(data_path)\n",
        "        # data = np.loadtxt(\"./input/data.csv\", delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        try :\n",
        "            self.y = torch.from_numpy(data.label.values)\n",
        "        except :\n",
        "            self.y = None\n",
        "        self.x = torch.from_numpy(data.loc[:,data.columns != \"label\"].values).unsqueeze(1).view(data.shape[0], 1, 28, 28)\n",
        "        self.n_samples=data.shape[0]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__pycache__', 'input', 'trained_models', 'runs', '.git', 'run_options.py', 'Kaggle_digit_recogniser.py', 'networkfc.py', 'network_fc_template', 'kaggle_submission.csv', 'analytics.py', 'networkconv.py', 'results.json', 'results.csv', 'README.md', 'tensorfromdata.py', 'dataloader.py', 'test.py']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAtgPYqQHbUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Run():\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.run_params = None\n",
        "        self.run_count = 0\n",
        "        self.run_data = []\n",
        "        self.run_start_time = None\n",
        "        self.run_duration = None\n",
        "        self.network = None\n",
        "        self.data_loader = None\n",
        "        self.tb = None\n",
        "        \n",
        "    #params = dictionary of parameters for DataLoader and optim\n",
        "    # dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn)\n",
        "    \n",
        "    def run_parameters(self, params):\n",
        "        Run = namedtuple('Run', params.keys())\n",
        "        runs = []\n",
        "        for v in product(*params.values()):\n",
        "            runs.append(Run(*v))\n",
        "        return runs\n",
        "    \n",
        "    def run_begin(self, run, network, data_loader):\n",
        "        \n",
        "        self.run_count += 1\n",
        "        self.run_start_time = time.time()\n",
        "        self.run_params = run\n",
        "        self.tb = SummaryWriter(comment=f'-{run}')\n",
        "        self.network = network\n",
        "        self.data_loader = data_loader\n",
        "        \n",
        "        # images, labels = next(iter(self.data_loader))\n",
        "        # grid = torchvision.utils.make_grid(images)\n",
        "    \n",
        "        # self.tb.add_image('images', grid)\n",
        "        # self.tb.add_graph(self.network, images)\n",
        "    \n",
        "    def save(self, fileName):\n",
        "    \n",
        "        pd.DataFrame.from_dict( self.run_data, orient='columns').to_csv(f'{fileName}.csv')\n",
        "    \n",
        "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
        "        \n",
        "    def end_run(self):\n",
        "        self.tb.close()\n",
        "        self.epoch_count = 0\n",
        "        PATH = f'./trained_models/{self.run_params}.pth'\n",
        "        torch.save(self.network.state_dict(), PATH)\n",
        "    \n",
        "class Epochs(Run):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.epoch_count = 0\n",
        "        self.epoch_loss = 0\n",
        "        self.epoch_num_correct = 0\n",
        "        self.epoch_start_time = None\n",
        "        self.epoch_end_time = None\n",
        "        self.epoch_duration = None\n",
        "        \n",
        "        \n",
        "        \n",
        "    def start_epoch(self):\n",
        "        \n",
        "        self.epoch_start_time = time.time()\n",
        "        self.epoch_count += 1\n",
        "        self.epoch_loss = 0\n",
        "        \n",
        "    def end_epoch(self, r):\n",
        "        \n",
        "        self.epoch_duration = time.time() - self.epoch_start_time\n",
        "        r.run_duration = time.time() - r.run_start_time\n",
        "    \n",
        "        loss = self.epoch_loss / len(r.data_loader.dataset)\n",
        "        accuracy = self.epoch_num_correct / len(r.data_loader.dataset)\n",
        "        \n",
        "        \n",
        "        \n",
        "        r.tb.add_scalar('Loss', loss, self.epoch_count)\n",
        "        r.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
        "    \n",
        "        # for name, param in r.network.named_parameters():\n",
        "        #     r.tb.add_histogram(name, param, self.epoch_count)\n",
        "        #     r.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "            \n",
        "        results = dict()\n",
        "        results[\"run\"] = r.run_count\n",
        "        results[\"epoch\"] = self.epoch_count\n",
        "        results['loss'] = loss\n",
        "        results[\"accuracy\"] = accuracy\n",
        "        results['epoch duration'] = self.epoch_duration\n",
        "        results['run duration'] = r.run_duration\n",
        "        for k,v in r.run_params._asdict().items(): results[k] = v\n",
        "        r.run_data.append(results)\n",
        "        \n",
        "        df = pd.DataFrame.from_dict(r.run_data, orient='columns')\n",
        "      \n",
        "        self.epoch_loss = 0\n",
        "        self.epoch_num_correct = 0\n",
        "        \n",
        "        \n",
        "    def track_loss(self, loss, batch_size):\n",
        "        self.epoch_loss += loss.item() * batch_size\n",
        "        \n",
        "    def track_num_correct(self, preds, labels):\n",
        "        self.epoch_num_correct += correct(preds, labels)\n",
        "        \n",
        "        \n",
        "        \n",
        "class FcLayers():\n",
        "    \n",
        "    def __init__(self, n_in, output, nb_of_layers, act_fonction):\n",
        "        \n",
        "        self.n_layer = 1\n",
        "        self.name = (f'fc{self.n_layer}')\n",
        "        self.in_features = n_in\n",
        "        self.n_delta = n_in // nb_of_layers\n",
        "        self.out_features = n_in-self.n_delta\n",
        "        self.output = output\n",
        "        self.nb_of_layers = nb_of_layers\n",
        "        self.layer_list = []\n",
        "        self.act_fonction=\"relu\"\n",
        "        \n",
        "    def next_layer_parameters(self):\n",
        "        \n",
        "        self.n_layer += 1\n",
        "        self.name = (f'fc{self.n_layer}')\n",
        "        self.in_features = self.out_features\n",
        "        self.out_features -= self.n_delta\n",
        "        \n",
        "        \n",
        "    def layer_creation(self):\n",
        "        for i in range(self.nb_of_layers):\n",
        "            if i == self.nb_of_layers-1 :\n",
        "                self.name = \"out\"\n",
        "                self.out_features = self.output\n",
        "            self.layer_list.append((self.name, self.in_features, self.out_features))\n",
        "            self.next_layer_parameters()\n",
        "            \n",
        "            \n",
        "    def network_creator(self):\n",
        "        \n",
        "        text_layer = str()\n",
        "        text_forward =str()\n",
        "        l=1\n",
        "        \n",
        "        for name, in_feat, out_feat in self.layer_list :\n",
        "            \n",
        "            text_layer =text_layer + f'self.{name} = nn.Linear(in_features= {in_feat}, out_features={out_feat})\\n        '\n",
        "            text_forward = text_forward + f'#layer {l} \\n        x = self.{name}(x) \\n        x = F.{self.act_fonction}(x)\\n\\n        '\n",
        "            # layer_list.append(f'self.{name} = nn.Linear(in_features= {in_feat}, out_features={out_feat}')\n",
        "            # text_layer = '\\n'.join(layer_list)\n",
        "            l += 1\n",
        "        \n",
        "        file = open(\"network_fc_template\", \"r\")\n",
        "        text = file.read()\n",
        "        text = text.replace('layers_line', text_layer)\n",
        "        text = text.replace('forward_line', text_forward)\n",
        "        file = open(f\"networkfc.py\", \"w\")\n",
        "        file.write(text)\n",
        "        file.close()\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzuvVeKSHgNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct(preds, labels):\n",
        "    c=torch.eq(preds.argmax(dim=1),labels,out=torch.tensor([]))\n",
        "    return c.sum().item()\n",
        "\n",
        "def get_all_preds(model, loader):\n",
        "        all_preds = torch.tensor([])\n",
        "        for batch in loader:\n",
        "            images, labels = batch\n",
        "            preds = model(images.float())\n",
        "            all_preds = torch.cat((all_preds, preds),dim=0)\n",
        "            return all_preds\n",
        "  \n",
        "def confusion_matrix():\n",
        "    with torch.no_grad():    \n",
        "        prediction_loader = DataLoader(dataset=dataset,batch_size=len(dataset),shuffle=False)\n",
        "        train_preds = get_all_preds(network, prediction_loader)\n",
        "    \n",
        "    preds_labels = torch.stack((dataset.y, train_preds.argmax(dim=1)),dim=1)\n",
        "        \n",
        "    \n",
        "    conf_matrix = torch.zeros(10,10,dtype=torch.int32)\n",
        "    for i in preds_labels:\n",
        "        l, p = i.tolist()\n",
        "        conf_matrix[l,p] = conf_matrix[l,p] + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ye0j9WpHwRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FullConNetwork(nn.Module):\n",
        "    def __init__(self, images, kernel_size, nb_of_fclayers, out_feat):\n",
        "        \n",
        "        self.in_channels = images.shape[1]\n",
        "        self.img_size = images.shape[2]*images.shape[3]\n",
        "        self.new_feat_map = self.in_channels*2\n",
        "        self.kernel_size = kernel_size\n",
        "        self.layer_output = images.shape[2]\n",
        "        self.n_delta = None\n",
        "        self.out_features = None\n",
        "        self.output = out_feat\n",
        "        self.nb_of_fclayers = nb_of_fclayers\n",
        "        \n",
        "        # super function. It inherits from nn.Module and we can access everythink in nn.Module\n",
        "        super(FullConNetwork,self).__init__()\n",
        "        # Function.\n",
        "    # determine number of convolution according to size of image\n",
        "        self.nb_of_conv = int(math.log(self.img_size)/math.log(2))\n",
        "        \n",
        "    # creating layers\n",
        "        \n",
        "        self.cnn = []\n",
        "        for n in range(self.nb_of_conv) :\n",
        "            self.cnn += [nn.Conv2d(self.in_channels, self.new_feat_map, self.kernel_size),\n",
        "                    nn.BatchNorm2d(self.new_feat_map),\n",
        "                    nn.LeakyReLU()]\n",
        "            \n",
        "            self.in_channels = self.new_feat_map\n",
        "            self.new_feat_map = self.new_feat_map*2\n",
        "            self.layer_output = (self.layer_output-self.kernel_size)+1\n",
        "            print(self.layer_output)\n",
        "        \n",
        "        self.cnn = nn.Sequential(*self.cnn)\n",
        "        \n",
        "        self.n_delta = self.layer_output // nb_of_fclayers\n",
        "        self.out_features = self.layer_output - self.n_delta\n",
        "        \n",
        "        \n",
        "        self.fc = []\n",
        "        for n in range(self.nb_of_fclayers) :\n",
        "            if n == self.nb_of_fclayers-1 :\n",
        "                self.out_features = self.output\n",
        "            self.fc += [nn.Linear(in_features = self.layer_output, out_features = self.out_features)\n",
        "                        , nn.LeakyReLU()]     \n",
        "            self.layer_output -= self.n_delta\n",
        "            self.out_features -= self.n_delta\n",
        "            \n",
        "        self.fc = nn.Sequential(*self.fc)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.cnn(x)\n",
        "        print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        print(x.shape)\n",
        "        x = self.fc(x)\n",
        "        print(x.shape)\n",
        "        return x\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnzHNjJnA-Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af5da84b-89d5-468c-eca7-12679b85e925"
      },
      "source": [
        "\n",
        "out_feat = 10\n",
        "\n",
        "\n",
        "\n",
        "#parameters = dictionary of parameters for DataLoader and optim (dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn)\n",
        "parameters = dict(\n",
        "    lr = [0.01]\n",
        "    ,batch_size = [1000]\n",
        "    ,shuffle = [False]\n",
        "    ,epochs = [20]\n",
        "    ,nb_of_fclayers = [x for x in range(4, 20, 4)]\n",
        "    # ,act_fonction=[\"relu\",\"glu\",\"tanh\",\"sigmoid\",\"softmax\"]\n",
        "    ,kernel_size = [2, 4])\n",
        "\n",
        "r = Run()\n",
        "runs = r.run_parameters(parameters)\n",
        "\n",
        "data_path = \"input/train.csv\"\n",
        "train_set = TensorDataset(data_path)\n",
        "\n",
        "\n",
        "\n",
        "for run in runs:\n",
        "    print(run)\n",
        "  \n",
        "    data_loader = DataLoader(dataset=train_set, batch_size=run.batch_size, shuffle=run.shuffle)\n",
        "    batch = next(iter(data_loader))\n",
        "    images, labels = batch\n",
        "    \n",
        "    cnnfc = FullConNetwork(images, run.kernel_size, run.nb_of_fclayers, out_feat)\n",
        "    \n",
        "    optimizer = optim.SGD(cnnfc.parameters(), lr=run.lr)\n",
        "    \n",
        "    r.run_begin(run, cnnfc, data_loader)\n",
        "   \n",
        "    e = Epochs()\n",
        "    for epoch in range(run.epochs):\n",
        "          \n",
        "        e.start_epoch()\n",
        "        \n",
        "        for batch in data_loader :\n",
        "            \n",
        "            images, labels = batch\n",
        "            \n",
        "            #runs the batch in the CNN\n",
        "            preds=cnnfc(images.float())\n",
        "            \n",
        "            \n",
        "            #calculate Loss\n",
        "            loss = F.cross_entropy(preds,labels)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #BackProp\n",
        "            loss.backward()\n",
        "            \n",
        "            #update weights\n",
        "            optimizer.step()\n",
        "        \n",
        "            e.track_loss(loss, run.batch_size)\n",
        "            e.track_num_correct(preds, labels)\n",
        "            \n",
        "            \n",
        "        print(\"epoch:\", e.epoch_count ,\"/  total_correct:\", e.epoch_num_correct, \"/  Loss:\", e.epoch_loss )\n",
        "        e.end_epoch(r)\n",
        "        \n",
        "    \n",
        "    r.end_run()\n",
        "    r.save('results')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run(lr=0.01, batch_size=1000, shuffle=False, epochs=20, nb_of_fclayers=4, kernel_size=2)\n",
            "27\n",
            "26\n",
            "25\n",
            "24\n",
            "23\n",
            "22\n",
            "21\n",
            "20\n",
            "19\n",
            "tensor([[[[-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.7054e-03,\n",
            "           -1.0404e-02,  6.6918e-01],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -7.3460e-03,\n",
            "           -2.6671e-03,  5.0276e-01],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -7.5929e-03,\n",
            "           -9.1682e-03,  1.0586e+00],\n",
            "          ...,\n",
            "          [ 4.3008e-01,  1.1710e+00,  1.6175e+00,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          [ 9.1403e-01,  1.5525e+00, -2.6025e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          [ 1.0603e-01,  2.2050e+00,  9.3822e-01,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03]],\n",
            "\n",
            "         [[-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -7.7300e-03,\n",
            "            8.0276e-02,  3.4623e-01],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -9.2311e-03,\n",
            "           -8.3132e-04, -1.2517e-02],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.3344e-03,\n",
            "            6.0935e-01,  3.7186e-01],\n",
            "          ...,\n",
            "          [ 2.2504e-01, -9.7841e-03,  2.3817e-01,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          [ 1.1329e-02, -8.8853e-03, -1.3228e-02,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          [ 1.2492e+00,  8.5534e-01, -1.4568e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03]],\n",
            "\n",
            "         [[ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ..., -1.1006e-02,\n",
            "           -5.3126e-03,  8.1965e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  1.5036e+00,\n",
            "            9.8201e-01,  6.4987e-03],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  3.1796e-01,\n",
            "            5.1926e-01, -1.0367e-02],\n",
            "          ...,\n",
            "          [ 4.7219e-01,  4.7709e-02, -1.2752e-02,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          [ 1.7989e-01,  3.4805e-01, -1.1661e-02,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          [-7.8197e-04,  1.4679e-01, -6.7499e-03,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4242e-03, -1.4242e-03, -1.4242e-03,  ...,  9.4093e-01,\n",
            "            3.9813e-01, -2.3183e-03],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ...,  8.5738e-01,\n",
            "            7.9049e-01, -1.3037e-02],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -2.0063e-03,\n",
            "           -9.0176e-04, -5.3418e-03],\n",
            "          ...,\n",
            "          [ 4.9360e-01, -8.1888e-03, -4.4253e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          [ 8.0377e-01, -8.1892e-03, -5.8341e-04,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          [-4.4288e-03, -6.7541e-03, -5.5445e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03]],\n",
            "\n",
            "         [[-1.8455e-03, -1.8455e-03, -1.8455e-03,  ...,  8.5452e-01,\n",
            "           -4.3026e-03,  8.7176e-01],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.1217e-02,\n",
            "            7.7468e-01, -8.6193e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ...,  3.9355e-02,\n",
            "            2.5139e-01,  5.1764e-01],\n",
            "          ...,\n",
            "          [-4.7393e-03,  2.8352e-01, -2.0225e-02,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          [ 7.5232e-02, -2.1572e-03, -2.2260e-02,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          [-1.3480e-03,  1.1987e+00, -5.0001e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03]],\n",
            "\n",
            "         [[-5.4681e-03, -5.4681e-03, -5.4681e-03,  ...,  2.8344e-01,\n",
            "           -5.0549e-03, -1.4658e-02],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -2.8241e-03,\n",
            "           -6.9680e-03,  1.8987e-01],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -4.9613e-03,\n",
            "            5.9686e-01, -2.5216e-03],\n",
            "          ...,\n",
            "          [-1.7869e-03,  9.7386e-01, -2.3066e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          [-3.0148e-03,  2.3752e+00, -1.3382e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          [ 6.0471e-01,  1.0047e-01, -2.5083e-02,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03]]],\n",
            "\n",
            "\n",
            "        [[[-6.4472e-03, -5.0997e-03, -4.2582e-03,  ..., -7.9600e-03,\n",
            "           -8.3793e-03, -5.9476e-03],\n",
            "          [-2.4884e-03, -1.4871e-03,  1.0755e+00,  ...,  5.4726e-01,\n",
            "           -4.9317e-03, -6.8455e-03],\n",
            "          [-1.4079e-04,  4.6246e-01,  4.9500e-01,  ..., -1.2776e-02,\n",
            "            1.5580e-01, -9.2343e-03],\n",
            "          ...,\n",
            "          [ 1.4537e+00,  3.0249e+00,  4.0645e+00,  ..., -1.9002e-03,\n",
            "           -5.1900e-03, -5.6609e-04],\n",
            "          [-4.3602e-03,  2.1485e+00,  2.8950e+00,  ..., -6.4434e-03,\n",
            "           -8.3056e-05,  2.2376e-02],\n",
            "          [-5.8130e-03, -1.3805e-03,  1.3691e+00,  ...,  3.0634e-01,\n",
            "            2.7388e-01, -5.6925e-03]],\n",
            "\n",
            "         [[-4.3790e-03, -5.6717e-03, -5.7637e-03,  ...,  2.0468e-01,\n",
            "           -8.2595e-04, -2.3606e-03],\n",
            "          [-2.8748e-03, -1.5256e-03, -1.4797e-02,  ..., -2.0273e-03,\n",
            "            2.9149e-01, -4.3056e-03],\n",
            "          [-1.4940e-03, -4.0153e-03,  9.5414e-01,  ...,  7.0431e-01,\n",
            "           -7.7203e-03, -1.2729e-03],\n",
            "          ...,\n",
            "          [ 7.3087e-01,  1.8735e+00, -2.6346e-02,  ...,  1.7923e+00,\n",
            "            2.5965e-01,  7.8692e-01],\n",
            "          [ 3.1203e-01,  8.9044e-01, -5.4286e-03,  ...,  8.7636e-01,\n",
            "           -7.7104e-03,  3.7140e-01],\n",
            "          [-6.2416e-03,  7.7555e-01,  1.1603e+00,  ...,  9.3493e-01,\n",
            "            8.4355e-01,  3.6343e-01]],\n",
            "\n",
            "         [[ 1.7565e-01,  8.2702e-01, -2.7904e-03,  ...,  2.2564e-01,\n",
            "            4.9198e-01,  4.9262e-01],\n",
            "          [-2.7963e-04,  4.3249e-01,  1.2859e+00,  ...,  3.3423e-01,\n",
            "            1.2963e-01,  4.5130e-01],\n",
            "          [ 5.6147e-01, -1.4466e-03, -6.5775e-03,  ..., -3.5219e-03,\n",
            "            1.4721e+00,  2.5555e-01],\n",
            "          ...,\n",
            "          [-7.2043e-03, -2.2423e-02, -2.6354e-02,  ...,  8.2368e-02,\n",
            "            2.2337e+00,  8.0607e-01],\n",
            "          [ 5.1767e-01, -7.8995e-03, -2.6350e-02,  ...,  1.0753e+00,\n",
            "           -1.5988e-03,  4.1781e-01],\n",
            "          [ 3.2582e-01,  2.5685e-01, -1.0202e-02,  ..., -1.0142e-03,\n",
            "            6.2679e-01,  7.2915e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2017e-03,  5.9750e-02, -3.3884e-03,  ..., -4.2473e-04,\n",
            "           -1.0344e-03,  4.5154e-01],\n",
            "          [-2.5264e-03,  5.9574e-01, -9.3188e-03,  ..., -1.1658e-02,\n",
            "            2.1470e-01,  3.3143e-01],\n",
            "          [ 3.7914e-01, -7.8483e-03, -2.1107e-02,  ..., -5.2175e-03,\n",
            "           -1.5100e-03,  2.8556e-01],\n",
            "          ...,\n",
            "          [-3.7039e-03, -1.4449e-02,  6.3868e-02,  ..., -5.4260e-03,\n",
            "           -1.4945e-03, -1.0915e-02],\n",
            "          [-6.1297e-03,  3.9780e-01, -2.0909e-02,  ...,  5.5797e-01,\n",
            "           -5.9484e-03,  6.6784e-02],\n",
            "          [-3.5889e-03, -8.1057e-03, -4.9040e-03,  ...,  1.6618e+00,\n",
            "            8.2473e-01,  4.0138e-01]],\n",
            "\n",
            "         [[-3.7061e-03, -1.0184e-02,  1.0849e+00,  ..., -1.1029e-03,\n",
            "           -3.3546e-03, -5.8813e-03],\n",
            "          [-4.6690e-05,  8.7546e-01, -8.5726e-03,  ..., -9.5275e-03,\n",
            "            2.1609e-01, -5.2086e-03],\n",
            "          [-5.5959e-03, -4.3936e-04, -1.7311e-02,  ..., -6.0263e-04,\n",
            "           -3.6513e-03, -1.2378e-03],\n",
            "          ...,\n",
            "          [-3.7466e-03,  3.4950e+00,  1.6612e+00,  ..., -9.2328e-03,\n",
            "           -9.8249e-03, -8.9153e-04],\n",
            "          [ 2.9514e-01, -1.8176e-03,  3.1632e+00,  ..., -2.5565e-03,\n",
            "           -7.6601e-03,  1.8368e-01],\n",
            "          [-3.6541e-03,  2.8344e-01,  1.1622e+00,  ...,  1.6931e-01,\n",
            "            2.1269e-01, -4.1555e-03]],\n",
            "\n",
            "         [[-1.6093e-03, -6.9432e-03,  4.0202e-01,  ..., -2.9522e-03,\n",
            "           -5.5329e-03, -3.1562e-03],\n",
            "          [-6.0552e-03,  2.0441e+00, -3.3587e-03,  ..., -1.3815e-03,\n",
            "           -3.8755e-03, -4.5395e-03],\n",
            "          [ 1.1954e+00,  1.0798e+00,  7.6108e-01,  ..., -1.0770e-03,\n",
            "           -4.0795e-03, -1.2952e-03],\n",
            "          ...,\n",
            "          [ 4.7773e-01, -1.7829e-02, -3.5947e-02,  ...,  5.9630e-02,\n",
            "           -5.8439e-03,  2.0330e-01],\n",
            "          [-3.2678e-03,  3.9393e-01, -2.1572e-02,  ...,  8.6519e-01,\n",
            "            5.4655e-01, -6.5141e-03],\n",
            "          [-3.4463e-03, -1.0626e-03, -2.7343e-03,  ...,  7.5809e-01,\n",
            "           -7.4493e-04,  3.6860e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          ...,\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -8.2240e-03,\n",
            "           -8.2240e-03, -8.2240e-03]],\n",
            "\n",
            "         [[-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          ...,\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.2969e-03,\n",
            "           -1.2969e-03, -1.2969e-03]],\n",
            "\n",
            "         [[ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          ...,\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  4.7445e-01,\n",
            "            4.7445e-01,  4.7445e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          ...,\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.4242e-03,\n",
            "           -1.4242e-03, -1.4242e-03]],\n",
            "\n",
            "         [[-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          ...,\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.8455e-03,\n",
            "           -1.8455e-03, -1.8455e-03]],\n",
            "\n",
            "         [[-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          ...,\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.4681e-03,\n",
            "           -5.4681e-03, -5.4681e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.5035e-03, -8.2838e-03, -6.1795e-03,  ..., -8.5763e-03,\n",
            "           -8.3081e-03, -8.1787e-03],\n",
            "          [-7.8588e-03, -5.6158e-03, -3.3705e-03,  ..., -9.4127e-03,\n",
            "           -8.9100e-03, -8.4087e-03],\n",
            "          [-5.7671e-03, -9.4617e-03, -8.8787e-03,  ..., -5.9804e-03,\n",
            "           -9.8537e-03, -8.9089e-03],\n",
            "          ...,\n",
            "          [-8.2240e-03, -8.2207e-03, -7.6249e-03,  ..., -9.4240e-03,\n",
            "           -8.5405e-03, -8.2240e-03],\n",
            "          [-8.2240e-03, -8.2093e-03, -5.9499e-03,  ..., -6.6935e-03,\n",
            "           -7.9042e-03, -8.2240e-03],\n",
            "          [-8.2240e-03, -8.1946e-03, -6.6953e-03,  ..., -8.1901e-03,\n",
            "           -8.3412e-03, -8.2240e-03]],\n",
            "\n",
            "         [[-8.9708e-04, -1.7148e-03, -1.7717e-03,  ..., -1.1378e-03,\n",
            "           -1.4420e-03, -1.2993e-03],\n",
            "          [-9.6665e-04, -1.3646e-03, -8.8569e-04,  ...,  8.0751e-02,\n",
            "           -8.3071e-04, -1.3554e-03],\n",
            "          [ 1.4745e-01, -1.7793e-03, -6.3288e-03,  ..., -2.6849e-03,\n",
            "            3.4553e-02, -1.2649e-03],\n",
            "          ...,\n",
            "          [-1.2969e-03, -1.2937e-03, -1.9256e-03,  ...,  2.0990e-02,\n",
            "           -1.5606e-03, -1.2969e-03],\n",
            "          [-1.2969e-03, -1.2909e-03,  7.4124e-03,  ...,  1.7953e-01,\n",
            "           -1.5120e-03, -1.2969e-03],\n",
            "          [-1.2969e-03, -1.2879e-03, -2.7285e-03,  ..., -1.7365e-03,\n",
            "           -1.2922e-03, -1.2969e-03]],\n",
            "\n",
            "         [[ 3.8549e-01,  4.2946e-01,  5.6469e-01,  ...,  4.9366e-01,\n",
            "            4.6638e-01,  4.6420e-01],\n",
            "          [ 2.4354e-01,  6.8720e-01,  5.2683e-01,  ...,  5.5955e-01,\n",
            "            4.7930e-01,  4.6047e-01],\n",
            "          [ 3.9621e-01,  1.3712e-01,  4.5642e-01,  ...,  5.8457e-01,\n",
            "            4.4146e-01,  4.2088e-01],\n",
            "          ...,\n",
            "          [ 4.7445e-01,  4.7429e-01,  4.0240e-01,  ...,  2.2521e-01,\n",
            "            5.4898e-01,  4.7445e-01],\n",
            "          [ 4.7445e-01,  4.7426e-01,  5.1714e-01,  ...,  4.4157e-01,\n",
            "            5.3907e-01,  4.7445e-01],\n",
            "          [ 4.7445e-01,  4.7635e-01,  3.8859e-01,  ...,  5.3302e-01,\n",
            "            4.9523e-01,  4.7445e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.3046e-04,  3.6186e-02, -2.3187e-03,  ..., -8.1507e-04,\n",
            "           -1.1775e-03, -1.4184e-03],\n",
            "          [-1.4423e-03, -1.6593e-03, -3.2618e-03,  ...,  4.3818e-03,\n",
            "           -1.3570e-04, -1.1265e-03],\n",
            "          [ 7.4783e-02, -1.5463e-03, -1.2168e-05,  ...,  3.9470e-01,\n",
            "            1.4731e-01, -7.9202e-04],\n",
            "          ...,\n",
            "          [-1.4242e-03, -1.4242e-03, -1.9602e-03,  ..., -1.0649e-03,\n",
            "           -1.3442e-03, -1.4242e-03],\n",
            "          [-1.4242e-03, -1.4246e-03, -2.2756e-03,  ...,  2.6600e-02,\n",
            "           -9.1794e-04, -1.4242e-03],\n",
            "          [-1.4242e-03, -1.4342e-03, -1.8920e-03,  ..., -1.0457e-03,\n",
            "           -1.4599e-03, -1.4242e-03]],\n",
            "\n",
            "         [[-1.1881e-03, -2.9304e-03, -4.5991e-03,  ..., -1.7644e-03,\n",
            "           -1.5702e-03, -1.8207e-03],\n",
            "          [-2.8297e-03, -5.9281e-03, -7.7842e-03,  ..., -6.9525e-04,\n",
            "           -1.6212e-03, -1.4923e-03],\n",
            "          [-9.5817e-03, -4.5416e-03, -4.8856e-04,  ..., -5.9110e-03,\n",
            "           -7.8204e-04, -1.0735e-03],\n",
            "          ...,\n",
            "          [-1.8455e-03, -1.8431e-03, -1.0977e-03,  ...,  9.2283e-02,\n",
            "           -4.0939e-04, -1.8455e-03],\n",
            "          [-1.8455e-03, -1.8301e-03, -2.6437e-03,  ..., -1.2869e-03,\n",
            "           -1.4569e-03, -1.8455e-03],\n",
            "          [-1.8455e-03, -1.8113e-03, -3.2155e-03,  ..., -8.6584e-04,\n",
            "           -1.7121e-03, -1.8455e-03]],\n",
            "\n",
            "         [[-5.2000e-03, -6.6886e-03, -7.6212e-03,  ..., -4.7483e-03,\n",
            "           -5.5191e-03, -5.4983e-03],\n",
            "          [-6.8716e-03, -7.9354e-03, -3.8459e-03,  ..., -3.4738e-03,\n",
            "           -4.5937e-03, -5.2974e-03],\n",
            "          [-5.6353e-03, -7.3500e-03, -3.2981e-03,  ..., -3.2903e-03,\n",
            "           -3.5837e-03, -4.6074e-03],\n",
            "          ...,\n",
            "          [-5.4681e-03, -5.4699e-03, -5.2719e-03,  ..., -5.0823e-03,\n",
            "           -5.1991e-03, -5.4681e-03],\n",
            "          [-5.4681e-03, -5.4641e-03, -5.8274e-03,  ..., -3.8555e-03,\n",
            "           -4.9242e-03, -5.4681e-03],\n",
            "          [-5.4681e-03, -5.4512e-03, -3.2867e-03,  ..., -5.7280e-03,\n",
            "           -5.3525e-03, -5.4681e-03]]],\n",
            "\n",
            "\n",
            "        [[[-8.2240e-03, -8.2240e-03, -8.2240e-03,  ...,  3.8939e-01,\n",
            "           -8.4398e-03, -6.6756e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.1509e-03,  ..., -2.1839e-03,\n",
            "           -1.4657e-02, -9.3983e-03],\n",
            "          [-8.2240e-03, -8.2227e-03, -7.9995e-03,  ..., -9.7500e-03,\n",
            "           -8.2926e-03, -8.5802e-03],\n",
            "          ...,\n",
            "          [ 2.1797e+00,  2.0377e+00,  6.1337e-01,  ..., -5.1287e-03,\n",
            "            6.1446e-02, -1.3047e-03],\n",
            "          [-3.3964e-04, -1.8259e-03,  2.4897e+00,  ..., -1.8860e-03,\n",
            "           -5.5832e-04, -1.3880e-02],\n",
            "          [-9.0240e-03,  6.8662e-02,  5.0565e-01,  ..., -5.7299e-03,\n",
            "           -1.1336e-02, -4.5221e-03]],\n",
            "\n",
            "         [[-1.2969e-03, -1.2969e-03, -1.2969e-03,  ..., -1.1854e-02,\n",
            "            4.3936e-01,  7.5945e-01],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.1415e-03,  ...,  3.8593e-01,\n",
            "           -1.0636e-03,  5.4532e-01],\n",
            "          [-1.2969e-03, -1.2932e-03, -1.4214e-03,  ...,  4.4785e-01,\n",
            "            5.3039e-01,  5.1012e-02],\n",
            "          ...,\n",
            "          [ 1.6835e+00, -2.9872e-03,  9.5613e-01,  ...,  1.3672e+00,\n",
            "           -6.6827e-03,  4.5850e-01],\n",
            "          [ 7.5210e-01,  1.9445e+00,  8.9494e-01,  ...,  8.5854e-01,\n",
            "           -2.4681e-03,  2.9966e-01],\n",
            "          [ 2.5850e-01,  2.1204e-01,  5.3881e-01,  ...,  1.6024e+00,\n",
            "            5.8321e-01,  5.2885e-01]],\n",
            "\n",
            "         [[ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ..., -1.2354e-02,\n",
            "            7.3406e-02,  6.3114e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7326e-01,  ...,  9.7642e-01,\n",
            "            1.1083e+00,  1.4745e-01],\n",
            "          [ 4.7445e-01,  4.7436e-01,  4.5371e-01,  ...,  2.0462e-01,\n",
            "            4.9697e-01,  2.3391e-01],\n",
            "          ...,\n",
            "          [-8.7082e-03, -7.2672e-03, -1.1579e-02,  ...,  9.3237e-01,\n",
            "           -4.3790e-03,  8.4963e-01],\n",
            "          [ 2.0626e-01, -1.2561e-03, -5.1181e-03,  ...,  3.3745e-01,\n",
            "            8.6439e-01,  1.5924e-01],\n",
            "          [ 5.2575e-01,  1.1715e-01, -1.2968e-03,  ..., -5.2547e-03,\n",
            "           -5.0340e-03,  1.9439e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4242e-03, -1.4242e-03, -1.4242e-03,  ..., -1.3299e-02,\n",
            "           -5.7018e-03, -3.8542e-04],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.3279e-03,  ..., -5.2290e-03,\n",
            "           -1.7562e-03,  1.8143e-01],\n",
            "          [-1.4242e-03, -1.4248e-03, -1.4427e-03,  ...,  6.2917e-02,\n",
            "            2.7354e-01, -1.4096e-03],\n",
            "          ...,\n",
            "          [ 1.3276e-01,  2.5902e-01,  1.0697e+00,  ...,  4.1794e-01,\n",
            "           -3.5459e-03,  1.3112e-01],\n",
            "          [-1.2509e-02, -1.9572e-02, -8.6563e-03,  ...,  1.0880e+00,\n",
            "            2.7795e-01,  7.1500e-02],\n",
            "          [-5.7232e-03, -1.0649e-02, -4.1901e-03,  ...,  9.3333e-01,\n",
            "            3.0617e-01,  5.5825e-02]],\n",
            "\n",
            "         [[-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -1.4975e-02,\n",
            "           -3.8190e-03, -6.1284e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8157e-03,  ..., -1.0027e-02,\n",
            "           -5.3782e-03, -2.5693e-04],\n",
            "          [-1.8455e-03, -1.8460e-03, -1.1961e-03,  ..., -3.3252e-04,\n",
            "           -2.1347e-04, -5.2951e-03],\n",
            "          ...,\n",
            "          [ 1.8664e-01,  8.1741e-01,  1.4919e+00,  ..., -6.5452e-03,\n",
            "           -6.7086e-04,  3.3141e-01],\n",
            "          [ 6.4683e-01,  9.7575e-01,  1.2047e+00,  ...,  7.6542e-01,\n",
            "           -3.4730e-04, -8.8027e-04],\n",
            "          [ 1.4815e-01,  6.7809e-01,  1.3888e+00,  ...,  1.9333e-01,\n",
            "           -3.1664e-03, -8.8251e-05]],\n",
            "\n",
            "         [[-5.4681e-03, -5.4681e-03, -5.4681e-03,  ...,  3.1450e-01,\n",
            "           -8.6733e-03, -4.3447e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4564e-03,  ..., -1.8568e-03,\n",
            "           -4.7146e-03, -5.9151e-03],\n",
            "          [-5.4681e-03, -5.4714e-03, -5.1875e-03,  ..., -3.1021e-03,\n",
            "           -3.9743e-03, -3.4873e-03],\n",
            "          ...,\n",
            "          [-1.1634e-02, -1.7768e-02,  1.2097e-01,  ..., -4.1080e-04,\n",
            "            9.1522e-01, -7.3229e-03],\n",
            "          [ 7.3950e-01, -8.0992e-03, -9.8369e-03,  ..., -1.0545e-03,\n",
            "           -5.7301e-03,  1.7802e-02],\n",
            "          [-4.4874e-03, -3.3190e-04, -7.2391e-03,  ...,  2.0099e-01,\n",
            "            2.5711e-01, -5.3559e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.8979e-03, -6.6578e-03, -7.9446e-03,  ..., -9.2664e-03,\n",
            "           -8.2877e-03, -8.2240e-03],\n",
            "          [-7.4058e-03, -7.1226e-03, -9.4955e-03,  ..., -5.5946e-03,\n",
            "           -8.6567e-03, -8.2133e-03],\n",
            "          [-7.6191e-03, -7.2892e-03, -9.4231e-03,  ..., -4.9780e-03,\n",
            "           -8.6446e-03, -8.1633e-03],\n",
            "          ...,\n",
            "          [-8.2846e-03, -8.0802e-03, -7.3196e-03,  ...,  7.1544e-02,\n",
            "           -6.1342e-03, -8.8804e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2239e-03,  ..., -1.9558e-03,\n",
            "           -1.1380e-02, -8.6739e-03],\n",
            "          [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ...,  1.7567e-01,\n",
            "           -7.2019e-03, -1.1038e-02]],\n",
            "\n",
            "         [[-1.6776e-03,  3.8614e-02, -1.9239e-03,  ..., -1.3043e-04,\n",
            "           -9.2020e-04, -1.2969e-03],\n",
            "          [-3.3051e-04, -1.2185e-03, -1.1166e-04,  ...,  1.1331e-01,\n",
            "            1.5475e-02, -1.2947e-03],\n",
            "          [-1.3223e-03,  1.3539e-01, -2.5015e-03,  ..., -4.6992e-04,\n",
            "            1.3081e-01, -1.2850e-03],\n",
            "          ...,\n",
            "          [-1.4109e-03, -1.5415e-03, -1.7350e-03,  ...,  6.5949e-01,\n",
            "            2.3540e-01,  1.6240e-01],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ...,  1.2424e+00,\n",
            "            5.2599e-01, -3.9530e-04],\n",
            "          [-1.2969e-03, -1.2969e-03, -1.2969e-03,  ...,  1.8591e-01,\n",
            "            6.8128e-01, -1.3871e-03]],\n",
            "\n",
            "         [[ 4.4196e-01,  3.7690e-01,  3.2349e-01,  ...,  4.5288e-01,\n",
            "            4.8252e-01,  4.7445e-01],\n",
            "          [ 5.1610e-01,  3.3333e-01,  1.3914e-02,  ...,  3.6896e-01,\n",
            "            5.4023e-01,  4.7314e-01],\n",
            "          [ 4.2550e-01,  3.5207e-01,  4.1718e-01,  ...,  3.8426e-01,\n",
            "            5.2664e-01,  4.6457e-01],\n",
            "          ...,\n",
            "          [ 4.7693e-01,  4.8595e-01,  4.7484e-01,  ...,  1.7390e-02,\n",
            "            5.2195e-01,  4.4884e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  2.2621e-01,\n",
            "            3.7525e-01,  3.2097e-01],\n",
            "          [ 4.7445e-01,  4.7445e-01,  4.7445e-01,  ...,  9.7688e-01,\n",
            "            5.2439e-03,  4.0103e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6130e-03, -9.9707e-04, -9.8264e-04,  ..., -8.5376e-04,\n",
            "           -1.1875e-03, -1.4242e-03],\n",
            "          [-2.1341e-03, -2.3259e-03, -5.2109e-03,  ...,  1.2027e-01,\n",
            "           -1.9867e-03, -1.4227e-03],\n",
            "          [-9.5768e-04, -1.1969e-03, -2.5665e-03,  ...,  1.2593e-01,\n",
            "           -2.1331e-03, -1.4146e-03],\n",
            "          ...,\n",
            "          [-1.5802e-03, -1.5899e-03, -8.4559e-04,  ...,  8.4854e-01,\n",
            "            2.1125e-01, -8.8438e-05],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4243e-03,  ...,  6.6415e-01,\n",
            "           -1.6248e-03, -1.2695e-03],\n",
            "          [-1.4242e-03, -1.4242e-03, -1.4242e-03,  ...,  2.3869e-01,\n",
            "            6.7487e-01, -3.2838e-03]],\n",
            "\n",
            "         [[-1.2235e-03, -2.4839e-03, -7.4189e-03,  ..., -8.2743e-04,\n",
            "           -1.6974e-03, -1.8455e-03],\n",
            "          [-1.9888e-03, -5.4892e-03, -2.8693e-03,  ..., -1.4100e-03,\n",
            "           -1.5328e-03, -1.8472e-03],\n",
            "          [-2.7237e-03, -3.4706e-03, -7.3419e-03,  ..., -3.7755e-03,\n",
            "           -1.9591e-03, -1.8500e-03],\n",
            "          ...,\n",
            "          [-1.8418e-03, -1.7130e-03, -1.6130e-03,  ...,  1.3211e-02,\n",
            "           -9.5560e-03, -1.0847e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ..., -3.3463e-03,\n",
            "           -3.5103e-03, -3.1981e-03],\n",
            "          [-1.8455e-03, -1.8455e-03, -1.8455e-03,  ...,  6.3190e-01,\n",
            "           -4.8239e-03, -5.1655e-03]],\n",
            "\n",
            "         [[-5.1225e-03, -6.2178e-03, -3.5902e-03,  ..., -4.5275e-03,\n",
            "           -5.0283e-03, -5.4681e-03],\n",
            "          [-5.9957e-03, -3.6080e-03, -3.4351e-03,  ..., -4.7710e-03,\n",
            "           -4.6919e-03, -5.4734e-03],\n",
            "          [-4.1326e-03, -4.9612e-03, -2.0617e-03,  ..., -2.2670e-03,\n",
            "           -4.8631e-03, -5.4725e-03],\n",
            "          ...,\n",
            "          [-5.4958e-03, -5.5471e-03, -5.3289e-03,  ...,  1.1924e-01,\n",
            "           -5.9570e-03, -4.6464e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -8.3632e-03,\n",
            "           -4.8620e-03, -5.3092e-03],\n",
            "          [-5.4681e-03, -5.4681e-03, -5.4681e-03,  ..., -5.3414e-03,\n",
            "            1.0533e-01, -5.5803e-03]]]], grad_fn=<LeakyReluBackward0>)\n",
            "tensor([[-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -5.4681e-03,\n",
            "         -5.4681e-03, -5.4681e-03],\n",
            "        [-6.4472e-03, -5.0997e-03, -4.2582e-03,  ...,  7.5809e-01,\n",
            "         -7.4493e-04,  3.6860e-01],\n",
            "        [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ..., -5.4681e-03,\n",
            "         -5.4681e-03, -5.4681e-03],\n",
            "        ...,\n",
            "        [-7.5035e-03, -8.2838e-03, -6.1795e-03,  ..., -5.7280e-03,\n",
            "         -5.3525e-03, -5.4681e-03],\n",
            "        [-8.2240e-03, -8.2240e-03, -8.2240e-03,  ...,  2.0099e-01,\n",
            "          2.5711e-01, -5.3559e-03],\n",
            "        [-7.8979e-03, -6.6578e-03, -7.9446e-03,  ..., -5.3414e-03,\n",
            "          1.0533e-01, -5.5803e-03]], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-26630bcbde54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m#runs the batch in the CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnnfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c4205d73f60d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1000 x 184832], m2: [19 x 15] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:136"
          ]
        }
      ]
    }
  ]
}